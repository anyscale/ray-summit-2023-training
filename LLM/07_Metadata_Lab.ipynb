{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbccac9f-034e-4a0b-bb94-378543b54037",
   "metadata": {},
   "source": [
    "# Metadata generation and querying lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f87c8-b5f0-4985-8421-0a7964af7a48",
   "metadata": {},
   "source": [
    "This lab is an opportunity to familiarize yourself with\n",
    "* Ray datasets\n",
    "* `map_batches`\n",
    "* generating metadata and providing it to a vector store\n",
    "* using metadata to improve query results\n",
    "\n",
    "If you're new to LLMs and Ray applications, focus on the core activities. If you've worked with LLMs and/or Ray before, you may have time to try the advanced activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86227722-835f-412f-be2a-e2c8785b4b02",
   "metadata": {},
   "source": [
    "## Core activities\n",
    "\n",
    "Throughout this lab, we're going to work with additional metadata for each of our documents. The metadata we'll add here is simple: it's just the length of the document. But we'll see that having (and using) even trivial metadata like this allows us to improve our search results.\n",
    "\n",
    "1. Copy and modify the code that uses Ray datasets and `.map_batches` to generate embeddings. Add to the ouput of the existing processing operation a column that contains the length of each document. *Hint: it will be another key-value pair in the dictionary representing the batch-processing output*\n",
    "1. Set the actor pool to a fixed size of 4 instead of the autoscaling version we used before (just to explore the `map_batches` API further)\n",
    "1. Using the ChromaDB docs and our existing code, generate a new Chroma collection that includes metadata for each doc. *Hint: the metadata will be supplied in a list alongside the docs and IDs. Each metadata record is a Python dictionary.*\n",
    "1. Modify the calls to `collection.query` to handle a `where` condition that filters against the metadata. *Hint: since we have length metadata, we can query for shorter or longer documents*\n",
    "1. Find a query where having and using the metadata makes a difference in the results -- ideally, producing better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012d7f12-417e-4f97-ae89-207787b048d6",
   "metadata": {},
   "source": [
    "## Advanced activity\n",
    "\n",
    "In this activity, we're not trying to produce any new output functionality.\n",
    "\n",
    "But instead of modifying the existing actor class that generates the embeddings to also generate metadata, we'll leave that code as-is and write a new function which adds the metadata and which we can use with `map_batches`\n",
    "\n",
    "1. Create a function (instead of a class) for transforming the batches of data. *Hint: the function signature will look like this: `add_metadata(batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]`*\n",
    "1. We're going to use the original embedding generator first, and then apply this add_metadata transformation to the data batches after they emerge from the previous `map_batches` step (with the new schema including doc, id, and embedding)\n",
    "1. We'll apply this second transformation via another call to `map_batches` but the call will be simpler than the previous one, since we don't have actors and Ray can handle scaling tasks on its own. We also don't need to worry about GPUs for this operation or specifying batch size.\n",
    "1. Collect the output via `to_numpy_refs` and then `ray.get` one of those chunks of data, inspect it, and verify it has the same strucure as the actor-based implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7525f0c-8133-4b91-80b0-f6b08dace5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
