{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee788c7-5783-4162-b1c8-00fe2a30de76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "import torch\n",
    "from ray import serve\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f5a0bd-5ae9-4aa8-8f36-1c080d7a15ba",
   "metadata": {},
   "source": [
    "# Autoscaling lab\n",
    "\n",
    "In this lab we'll explore\n",
    "* autoscaling\n",
    "* \"serverless\" deployments\n",
    "* replicas\n",
    "* resources\n",
    "* Ray dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1387da-9b12-420e-af47-921bff63cd04",
   "metadata": {},
   "source": [
    "## Core activity\n",
    "\n",
    "The main activity in this lab is to refactor basic Ray Serve chat deployment so that it supports autoscaling.\n",
    "\n",
    "Using the \"Review: scaling and performance\" section below as a reference, adjust the chat deployment so that it has the following properties\n",
    "* when not in use, it has no running replicas\n",
    "* it starts off with no running replicas (since it's not in use \"at launch time\")\n",
    "* it can scale to a maximum of 2 replicas\n",
    "\n",
    "Look at the Ray dashboard and note the deployment and replica states.\n",
    "\n",
    "By swapping in city names (e.g. 12 cities and 4 copies of each query), create a collection of 48 prompts and immediately call the model with all of them.\n",
    "\n",
    "Look at the Ray dashboard and log messages and note the scaling behavior and reporting of this scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f392f6-bebb-4e67-bdb9-318b9773522d",
   "metadata": {},
   "source": [
    "## Bonus activity\n",
    "\n",
    "See what happens if we try to scale to 3 replicas (knowing that we only have 2 x A10G GPUs in our cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2fdbe-fdaa-4ab4-90b7-d07dfa92cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5810916-6570-42ea-943c-510cf0d6b2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = '''You are a helpful assistant.### User: What is your favorite place to visit in San Francisco? ### Assistant:'''\n",
    "\n",
    "CHAT_MODEL = 'stabilityai/StableBeluga-7B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7feb3d-4b40-4ce0-841d-3e176b1a3e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@serve.deployment(ray_actor_options={\"num_gpus\": 1.0}, autoscaling_config={'min_replicas':0, 'max_replicas':2, 'initial_replicas':0})\n",
    "class Chat:\n",
    "    def __init__(self, model: str):\n",
    "        self._model =  pipeline(\"text-generation\", model=model, model_kwargs={\n",
    "                                        'torch_dtype':torch.float16,\n",
    "                                        'device_map':'auto',\n",
    "                                        \"cache_dir\": \"/mnt/local_storage\"})\n",
    "    \n",
    "    def get_response(self, message: str) -> str:\n",
    "        return self._model(message, max_length=200)\n",
    "\n",
    "handle = serve.run(Chat.bind(model=CHAT_MODEL), name='chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474bac2-a65d-49a8-bb22-18d124f9b0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = handle.get_response.remote(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c76dd15-c762-4dd9-bb0b-76c713955b56",
   "metadata": {},
   "source": [
    "*Look at Ray dashboard*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba41909-07f9-4a02-b427-3ad1423cf4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.get(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07084a-12f7-4645-b0b1-74da0da9cbf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cities = ['Atlanta', 'Boston', 'Chicago', 'Vancouver', 'Montreal', 'Toronto', 'Frankfurt', 'Rome', 'Warsaw', 'Cairo', 'Dar Es Salaam', 'Gaborone']\n",
    "prompts = [f'You are a helpful assistant.### User: What is your favorite place to visit in {city}? ### Assistant:' for city in cities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240fcaf-915f-4230-8fca-e98dd8f02b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = prompts * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e79d50-73ae-4ced-b9d7-1b977711eb8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "futures_iter = map(handle.get_response.remote, prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d669f1-d03c-4706-a293-fbaeff0c8c49",
   "metadata": {},
   "source": [
    "*Look at Ray dashboard and logs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae0913-be8e-4197-9959-d19edfd33e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "futures = list(futures_iter)\n",
    "\n",
    "futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d159d5a9-ad49-41e1-9b41-19480bbf7483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serve.delete('chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff7365e-cce5-4131-b9c0-3b32f2ef2172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serve.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
