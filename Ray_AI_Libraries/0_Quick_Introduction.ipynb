{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction to the Ray AI Libraries\n",
    "---\n",
    "\n",
    "<img src=\"https://technical-training-assets.s3.us-west-2.amazonaws.com/Ray_AI_Libraries/Ray+AI+Libraries.png\" width=\"70%\" loading=\"lazy\">\n",
    "\n",
    "Built on top of Ray Core, the Ray AI Libraries inherit all the performance and scalability benefits offered by Core while providing a convenient abstraction layer for machine learning. These Python-first native libraries allow ML practitioners to distribute individual workloads, end-to-end applications, and build custom use cases in a unified framework.\n",
    "\n",
    "The Ray AI Libraries bring together an ever-growing ecosystem of integrations with popular machine learning frameworks to create a common interface for development.\n",
    "\n",
    "|<img src=\"https://technical-training-assets.s3.us-west-2.amazonaws.com/Introduction_to_Ray_AIR/e2e_air.png\" width=\"100%\" loading=\"lazy\">|\n",
    "|:-:|\n",
    "|Ray AI Libraries enable end-to-end ML development and provides multiple options for integrating with other tools and libraries form the MLOps ecosystem.|\n",
    "\n",
    "**Table of Contents**\n",
    "1. [**Ray Data**](https://docs.ray.io/en/latest/data/dataset.html)  \n",
    "    * Scalable, framework-agnostic data loading and transformation across training, tuning, and inference.\n",
    "2. [**Ray Train**](https://docs.ray.io/en/latest/train/train.html)\n",
    "    * Distributed multi-node and multi-core training with fault tolerance that integrates with popular machine learning libraries.\n",
    "3. [**Ray Tune**](https://docs.ray.io/en/latest/tune/index.html)  \n",
    "    * Scales hyperparameter tuning to optimize model performance.\n",
    "4. [**Ray Serve**](https://docs.ray.io/en/latest/serve/index.html)  \n",
    "    * Deploys a model or ensemble of models for online inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick end-to-end example\n",
    "\n",
    "|Ray AIR Component|NYC Taxi Use Case|\n",
    "|:--|:--|\n",
    "|Ray Data|Ingest and transform raw data; perform batch inference by mapping the checkpointed model to batches of data.|\n",
    "|Ray Train|Use `Trainer` to scale XGBoost model training.|\n",
    "|Ray Tune|Use `Tuner` for hyperparameter search.|\n",
    "|Ray Serve|Deploy the model for online inference.|\n",
    "\n",
    "For this classification task, you will apply a simple [XGBoost](https://xgboost.readthedocs.io/en/stable/) (a gradient boosted trees framework) model to the June 2021 [New York City Taxi & Limousine Commission's Trip Record Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). This dataset contains over 2 million samples of yellow cab rides, and the goal is to predict whether a trip will result in a tip greater than 20% or not.\n",
    "\n",
    "**Dataset features**\n",
    "* **`passenger_count`**\n",
    "    * Float (whole number) representing number of passengers.\n",
    "* **`trip_distance`** \n",
    "    * Float representing trip distance in miles.\n",
    "* **`fare_amount`**\n",
    "    * Float representing total price including tax, tip, fees, etc.\n",
    "* **`trip_duration`**\n",
    "    * Integer representing seconds elapsed.\n",
    "* **`hour`**\n",
    "    * Hour that the trip started.\n",
    "    * Integer in the range `[0, 23]`\n",
    "* **`day_of_week`**\n",
    "    * Integer in the range `[1, 7]`.\n",
    "* **`is_big_tip`**\n",
    "    * Whether the tip amount was greater than 20%.\n",
    "    * Boolean `[True, False]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "from ray.train import ScalingConfig, RunConfig\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.train.xgboost import XGBoostPredictor\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune import Tuner, TuneConfig\n",
    "\n",
    "from ray import serve\n",
    "from starlette.requests import Request\n",
    "\n",
    "import requests, json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Read, preprocess with Ray Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ray.data.read_parquet(\"s3://anonymous@anyscale-training-data/intro-to-ray-air/nyc_taxi_2021.parquet\").repartition(16)\n",
    "\n",
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fit model with Ray Train__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = XGBoostTrainer(\n",
    "    label_column=\"is_big_tip\",\n",
    "    scaling_config=ScalingConfig(num_workers=4, use_gpu=False),\n",
    "    params={ \"objective\": \"binary:logistic\", },\n",
    "    datasets={\"train\": train_dataset, \"valid\": valid_dataset},\n",
    "    run_config=RunConfig(storage_path='/mnt/cluster_storage/')\n",
    ")\n",
    "\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Optimize hyperparameters with Ray Tune__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(trainer, \n",
    "            param_space={'params' : {'max_depth': tune.randint(2, 12)}},\n",
    "            tune_config=TuneConfig(num_samples=3, metric='train-logloss', mode='min'),\n",
    "            run_config=RunConfig(storage_path='/mnt/cluster_storage/'))\n",
    "\n",
    "checkpoint = tuner.fit().get_best_result().checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Batch inference with Ray Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OfflinePredictor:\n",
    "    def __init__(self):\n",
    "        import xgboost\n",
    "        self._model = xgboost.Booster()\n",
    "        self._model.load_model(checkpoint.path + '/model.json')\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        import xgboost\n",
    "        import pandas as pd\n",
    "        dmatrix = xgboost.DMatrix(pd.DataFrame(batch))    \n",
    "        outputs = self._model.predict(dmatrix)\n",
    "        return {\"prediction\": outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities = valid_dataset.drop_columns(['is_big_tip']).map_batches(OfflinePredictor, compute=ray.data.ActorPoolStrategy(size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities.take_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Online prediction with Ray Serve__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "class OnlinePredictor:\n",
    "    def __init__(self, checkpoint):\n",
    "        import xgboost\n",
    "        self._model = xgboost.Booster()\n",
    "        self._model.load_model(checkpoint.path + '/model.json')        \n",
    "        \n",
    "    async def __call__(self, request: Request) -> dict:\n",
    "        data = await request.json()\n",
    "        data = json.loads(data)\n",
    "        return {\"prediction\": self.get_response(data) }\n",
    "    \n",
    "    def get_response(self, data):\n",
    "        import pandas as pd\n",
    "        import xgboost\n",
    "        dmatrix = xgboost.DMatrix(pd.DataFrame(data, index=[0])) \n",
    "        return self._model.predict(dmatrix)\n",
    "\n",
    "handle = serve.run(OnlinePredictor.bind(checkpoint=checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = valid_dataset.take(1)[0]\n",
    "del(sample_input['is_big_tip'])\n",
    "del(sample_input['__index_level_0__'])\n",
    "\n",
    "requests.post(\"http://localhost:8000/\", json=json.dumps(sample_input)).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serve.shutdown()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
