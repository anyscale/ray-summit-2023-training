{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcad6b2-7dfd-4824-9ba9-8ceaf0598e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import serve\n",
    "import requests, json\n",
    "from starlette.requests import Request\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682e224e-1bb9-470c-b363-386ede0785a4",
   "metadata": {},
   "source": [
    "# Ray Serve\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "__Roadmap to Serve introduction__\n",
    "\n",
    "1. Implement a simple service\n",
    "1. Understand key concepts of Ray Serve including __deployments__\n",
    "1. Observe a running Serve __application__\n",
    "</div>\n",
    "\n",
    "Key principles behind Ray and its libraries are\n",
    "* Performance\n",
    "* Developer experience and simplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7250cc03-e52c-4e30-a262-8d8e0a5a0837",
   "metadata": {},
   "source": [
    "# Ray Serve\n",
    "\n",
    "Serve is a framework for serving ML applications\n",
    "\n",
    "<img src='https://technical-training-assets.s3.us-west-2.amazonaws.com/Ray_Serve/serve_architecture.png' width=700/>\n",
    "\n",
    "# Deployments\n",
    "\n",
    "`Deployment` is the fundamental user-facing element of serve.\n",
    "\n",
    "<img src='https://technical-training-assets.s3.us-west-2.amazonaws.com/Ray_Serve/deployment.png' width=600/>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "__Roadmap to initial chat app on serve__\n",
    "    \n",
    "1. Discover serve deployments via Hello World example\n",
    "1. Replace placeholder \"Hello World\" logic with Huggingface transformers chatbot\n",
    "1. Reserve GPU resources for our chatbot service\n",
    "</div>\n",
    "\n",
    "## Our First Service\n",
    "\n",
    "Letâ€™s jump right in and get something simple up and running on Ray\n",
    "Serve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb17a6-a71c-4a11-8ea8-b1b350a5fa1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "class Chat:\n",
    "    def __init__(self, msg: str):\n",
    "        self._msg = msg # initial state\n",
    "\n",
    "    async def __call__(self, request: Request) -> dict:\n",
    "        data = await request.json()\n",
    "        data = json.loads(data)\n",
    "        return {\"result\": self.get_response(data['input']) }\n",
    "    \n",
    "    def get_response(self, message: str) -> str:\n",
    "        return self._msg + message\n",
    "\n",
    "handle = serve.run(Chat.bind(msg=\"Yes... \"), name='hello_world')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a0cdb-822a-4439-aeab-9916dd8d059c",
   "metadata": {},
   "source": [
    "We can test it as an HTTP endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a80e9-c26f-48d2-8985-ef4eab4dc580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_json = '{ \"input\" : \"hello\" }'\n",
    "requests.post(\"http://localhost:8000/\", json = sample_json).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fde48c-a97f-425e-b304-cf455bc07737",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "__Lab activity: implement a web service with Ray Serve__\n",
    "    \n",
    "The following function will calculate the approximate loan payment for a car.\n",
    "    \n",
    "```python\n",
    " def monthly_payment(total_price, rate, years_of_loan):\n",
    "    n = 365.25 # compounding periods\n",
    "    total_paid = total_price * (((1 + ((rate/100.0)/n)) ** (n*years_of_loan)))\n",
    "    per_month = total_paid / (12 * years_of_loan)\n",
    "    return per_month\n",
    "```\n",
    "   \n",
    "<br/>\n",
    "Deploy this calculator as a web service with Ray Serve!\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1598e24-bf7f-47dc-96bc-10a7397490ef",
   "metadata": {},
   "source": [
    "## Key APIs and concepts\n",
    "\n",
    "Using Ray Serve, a single Ray cluster can host multiple __applications__\n",
    "\n",
    "__Applications__ are coarse-grained chunks of functionality *which can be independently upgraded* (i.e., without impacting other applications on the same cluster)\n",
    "\n",
    "An __application__ is made up of one or more __deployments__\n",
    "\n",
    "A __deployment__ is a smaller component which can\n",
    "* specify its own hardware are other resource requirements (like GPUs)\n",
    "* specify its own runtime environments (like libraries)\n",
    "* scale independently (including autoscaling)\n",
    "* maintain state (e.g., models)\n",
    "\n",
    "We can use __deployments__ to achieve *separation of concerns* -- e.g., separating different models, chunks of business logic, or data conversion\n",
    "\n",
    "__Ingress deployments__ are typically accessed via HTTP, while other supporting deployments are typically accessed at runtime via a Python `ServeHandle` -- allowing any Serve component (or Ray code) to interact directly with other components as needed\n",
    "\n",
    "We create a __deployment__ by applying the `@serve.deployment` decorator to a regular Python class or function. We create and start an __application__ by calling `serve.run` on a deployment (typically an ingress deployment)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06905e-d1cf-43a2-9ada-d8ebea204e6c",
   "metadata": {},
   "source": [
    "### Demo: calling a component from Python via a ServeHandle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a2710-b219-47b5-84a4-ca702eee270d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = handle.get_response.remote('hello')\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b55aee-36cf-4685-add1-17bb60f4ebcc",
   "metadata": {},
   "source": [
    "In order to support maximal performance, values from remote calls, such as our response string here, are returned as object references (a bit like futures or promises in some frameworks). If we want to block, wait for the result to be ready, and retrieve it, we can use `ray.get(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d2254f-f336-4772-8cb4-438edbea1f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.get(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49bf50-a248-42dc-ad54-424cc186c842",
   "metadata": {},
   "source": [
    "### Demo: observing application and deployment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f10df-9bf3-4ffb-8e57-1c9b8cac058c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! serve status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc43ed1-fcd1-4df7-8d40-e85d7347d658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serve.list_deployments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5ccabd-571f-40db-b163-327891ff3edf",
   "metadata": {},
   "source": [
    "Check the Ray dashboard as well to see more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e8484-50d1-401c-96c5-1e4247ecb7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serve.delete('hello_world')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67eb811-e7b5-4f7a-b826-b4536cff4212",
   "metadata": {},
   "source": [
    "## Let's serve our image classfier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d73bcbb-0ad3-4b0a-92f6-67af4d179b19",
   "metadata": {
    "tags": []
   },
   "source": [
    "We'll start with a sample image -- feel free to use your own as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b23ab6-b66e-443f-a246-1447723be0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = Image.open(\"/home/ray/default/AILibs/images/fish.png\") # from https://docs.ray.io/en/latest/_images/huggingface_vit_batch_prediction_25_4.png\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0133f69-946a-497c-865f-0b4a1332bcba",
   "metadata": {},
   "source": [
    "First, let's test inference locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d6179-f2a1-4343-b2fa-3e8ed1671d01",
   "metadata": {},
   "source": [
    "Our training checkpoints contain the path to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10a376d-7070-4e49-a8f0-946322edb271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/mnt/user_storage/TorchTrainer_2023-08-31_11-40-03/TorchTrainer_cc94d_00000_0_2023-08-31_11-40-03/checkpoint_000001/checkpoint'\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba62df9e-b248-4d63-a7c2-c3d8fe57cc38",
   "metadata": {
    "tags": []
   },
   "source": [
    "Set up the same featurizer that we trained with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6a259-3fbb-41bb-90fd-9d009e7eb7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = 'google/vit-base-patch16-224-in21k'\n",
    "\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe996e9b-1619-4639-8179-720f5996a8bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    features = feature_extractor(image, return_tensors='pt')\n",
    "    out = m(features['pixel_values']).logits\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe2c74-c653-4839-9b31-8a3513a68c4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now let's place the same logic inside a Ray Serve deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb5c5f-30ea-44d4-ada5-2dbe808af4e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "class Predict:\n",
    "    def __init__(self, featurizer_name, model_path):        \n",
    "        self._feature_extractor = ViTImageProcessor.from_pretrained(featurizer_name)\n",
    "        self._model = ViTForImageClassification.from_pretrained(model_path)        \n",
    "        self._model.eval()\n",
    "\n",
    "    def get_response(self, image):\n",
    "        with torch.no_grad():\n",
    "            inputs = self._feature_extractor(image, return_tensors='pt')\n",
    "            return self._model(inputs['pixel_values']).logits.numpy()\n",
    "    \n",
    "    async def __call__(self, request: Request):\n",
    "        import numpy as np\n",
    "        import io\n",
    "        from imageio import v3 as iio\n",
    "        from fastapi import Response\n",
    "\n",
    "        # async collect POST body\n",
    "        body = await request.body()\n",
    "        \n",
    "        # unpickle serialized data\n",
    "        image = pickle.loads(body)\n",
    "\n",
    "        # invoke existing business logic\n",
    "        return self.get_response(image)        \n",
    "\n",
    "app_handle = serve.run(Predict.bind(featurizer_name='google/vit-base-patch16-224-in21k',\n",
    "                                   model_path=path), name='classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1815d5d-c9f5-4aca-a919-99728b5b42b3",
   "metadata": {},
   "source": [
    "Test the core logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81663fd-553a-4626-8dc0-abf70b974cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.get(app_handle.get_response.remote(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f8b52-d5a5-4595-92fe-3b89b31a764c",
   "metadata": {},
   "source": [
    "Test via HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca4ebf6-4bf6-4bc0-afef-70dc34e5205f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.post(\"http://localhost:8000/\", data = pickle.dumps(image)) # uncompressed\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e2c301-38fc-4431-be05-2b1ae1a3e381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serve.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
